import os
import torch
import json
import logging
from pathlib import Path
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import (
    PdfPipelineOptions,
    PictureDescriptionApiOptions,
    AcceleratorOptions,
    AcceleratorDevice
)
from docling_core.types.doc.document import PictureItem, TableItem
from langchain_core.documents import Document

# --- åŸºç¤é…ç½® ---
torch._dynamo.config.disable = True
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

VLM_URL = 'http://localhost:11434/v1/chat/completions'
VLM_MODEL = 'granite3.2-vision'

def get_vlm_options():
    return PictureDescriptionApiOptions(
        url=VLM_URL,
        params=dict(model=VLM_MODEL, seed=42),
        prompt="è«‹ç”¨ä¸­æ–‡ç°¡æ½”æè¿°é€™å¼µåœ–è¡¨å…§å®¹èˆ‡é—œéµæ•¸æ“šï¼Œç´„ä¸‰å¥è©±ã€‚",
        timeout=120,
    )

def main():
    input_file = "File/1506.02640v5.pdf" 
    output_dir = Path("File/RAG_FINAL_PACKAGE")
    assets_dir = output_dir / "assets"
    assets_dir.mkdir(parents=True, exist_ok=True)

    pipeline_options = PdfPipelineOptions()
    pipeline_options.generate_picture_images = True
    pipeline_options.generate_table_images = True
    pipeline_options.enable_remote_services = True
    pipeline_options.do_picture_description = True
    pipeline_options.picture_description_options = get_vlm_options()
    pipeline_options.accelerator_options = AcceleratorOptions(num_threads=8, device=AcceleratorDevice.AUTO)

    converter = DocumentConverter(
        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)}
    )

    print(f"ğŸš€ æ­£åœ¨è§£æ PDF ä¸¦ç”¢ç”Ÿ AI æè¿°...")
    result = converter.convert(input_file)
    doc = result.document

    final_langchain_docs = []
    asset_counter = {}

    print("ğŸ“¦ æ­£åœ¨åŸ·è¡Œã€Œä¸‰åˆä¸€ã€ç‰©ä»¶å°è£...")
    for item, _ in doc.iterate_items():
        # 1. è™•ç†åœ–è¡¨ï¼ˆåœ–ç‰‡æˆ–è¡¨æ ¼ï¼‰
        if isinstance(item, (PictureItem, TableItem)):
            page_no = item.prov[0].page_no if item.prov else 0
            asset_counter[page_no] = asset_counter.get(page_no, 0) + 1
            
            prefix = "img" if isinstance(item, PictureItem) else "table"
            img_filename = f"page_{page_no}_{prefix}_{asset_counter[page_no]}.png"
            img_path = str(assets_dir / img_filename)
            
            # å„²å­˜åœ–ç‰‡
            if hasattr(item, 'image') and item.image:
                item.image.pil_image.save(img_path)

            # --- æå–ä¸‰è¦ç´  ---
            # A. åœ–ç‰‡åŸæœ¬çš„æè¿° (Caption)
            original_caption = item.caption.text if (hasattr(item, 'caption') and item.caption) else "ç„¡åŸç”Ÿæè¿°"
            
            # B. AI ç”Ÿæˆçš„æè¿° (VLM)
            ai_desc = ""
            if item.meta and item.meta.description:
                ai_desc = item.meta.description.text
            
            # C. åœ–ç‰‡è·¯å¾‘ (å·²ç¶“åœ¨ img_path è®Šæ•¸ä¸­)

            # å»ºç«‹ Document ç‰©ä»¶
            lc_doc = Document(
                # page_content æ˜¯çµ¦å‘é‡è³‡æ–™åº«æª¢ç´¢ç”¨çš„ï¼ŒæŠŠå…©ç¨®æè¿°éƒ½æ”¾é€²å»æ•ˆæœæœ€å¥½
                page_content=f"ã€åŸç”Ÿæ¨™é¡Œã€‘: {original_caption}\nã€AI å…§å®¹æè¿°ã€‘: {ai_desc}",
                metadata={
                    "source": input_file,
                    "is_visual": True,
                    "type": prefix,
                    "image_path": img_path,          # è·¯å¾‘
                    "original_caption": original_caption, # åŸç”Ÿæè¿°
                    "ai_description": ai_desc,       # AIæè¿°
                    "page_no": page_no
                }
            )
            final_langchain_docs.append(lc_doc)
            print(f"âœ… å·²å°è£: {img_filename}")

        # 2. è™•ç†ä¸€èˆ¬æ–‡å­—ï¼ˆéåœ–è¡¨ï¼‰
        elif hasattr(item, 'text') and item.text.strip():
            lc_doc = Document(
                page_content=item.text,
                metadata={
                    "source": input_file,
                    "is_visual": False,
                    "page_no": item.prov[0].page_no if item.prov else 0
                }
            )
            final_langchain_docs.append(lc_doc)

    # å„²å­˜ JSON åµéŒ¯æª”è®“ä½ ç¢ºèª metadata
    debug_output = [{"content": d.page_content, "meta": d.metadata} for d in final_langchain_docs]
    with open(output_dir / "check_metadata.json", "w", encoding="utf-8") as f:
        json.dump(debug_output, f, ensure_ascii=False, indent=4)

    print(f"\nâœ¨ å®Œå·¥ï¼å…±ç”¢ç”Ÿ {len(final_langchain_docs)} å€‹ç‰©ä»¶ã€‚")
    print(f"ğŸ” è«‹é–‹å•Ÿ {output_dir / 'check_metadata.json'} æª¢æŸ¥ Metadataï¼")

if __name__ == "__main__":
    main()